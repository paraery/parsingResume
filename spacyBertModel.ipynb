{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1G1uNQ4lbvcV-IsnyC2eoPII2kMdCCziS",
      "authorship_tag": "ABX9TyNlrr3xkMNckT9gxZ+Olj57",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paraery/parsingResume/blob/main/spacyBertModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('drive/MyDrive/textfortraining8.csv')\n",
        "lstTxt = df['text'].values.tolist()"
      ],
      "metadata": {
        "id": "ftsD8cnricza"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train=[]\n",
        "for a in lstTxt:\n",
        "    train.append(get_tokens_with_entities(a))"
      ],
      "metadata": {
        "id": "jaVY6hXBFKJ6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('drive/MyDrive/testData.csv')\n",
        "lstTest = df['text'].values.tolist()"
      ],
      "metadata": {
        "id": "7iKzz4BFvD_O"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def get_tokens_with_entities(raw_text: str):\n",
        "    # split the text by spaces only if the space does not occur between square brackets\n",
        "    # we do not want to split \"multi-word\" entity value yet\n",
        "    \n",
        "    raw_tokens = re.split(r\"\\s(?![^\\[]*\\])\", raw_text)\n",
        "\n",
        "    # a regex for matching the annotation according to our notation [entity_value](entity_name)\n",
        "    entity_value_pattern = r\"\\[(?P<value>.+?)\\]\\((?P<entity>.+?)\\)\"\n",
        "    entity_value_pattern_compiled = re.compile(entity_value_pattern, flags=re.I|re.M)\n",
        "\n",
        "    tokens_with_entities = []\n",
        "    lstEnt=[]\n",
        "    txt = raw_text\n",
        "    for raw_token in raw_tokens:\n",
        "        match = entity_value_pattern_compiled.match(raw_token)\n",
        "        if match:\n",
        "            raw_entity_name, raw_entity_value = match.group(\"entity\"), match.group(\"value\")\n",
        "            \n",
        "            # we prefix the name of entity differently\n",
        "            # B- indicates beginning of an entity\n",
        "            # I- indicates the token is not a new entity itself but rather a part of existing one\n",
        "            #txt = raw_text[raw_text.find(str(raw_entity_value))-1 : ]\n",
        "            txt = raw_text.replace(raw_text[int(raw_text.find(raw_entity_value))-1],'',1)\n",
        "            txt = txt.replace('](PERSON)','')\n",
        "            #print(txt)\n",
        "            lstdata = ()\n",
        "            entity_name = f\"{raw_entity_name}\"\n",
        "            entName = createSubEntity(txt.find(raw_entity_value), txt.find(raw_entity_value) + len(raw_entity_value), entity_name)\n",
        "            lstEnt.append(entName)\n",
        "                #tokens_with_entities.append((raw_entity_token, entity_name))\n",
        "    d={\"entities\": lstEnt}\n",
        "            #print(lstEnt)\n",
        "    lstdata=(txt,d)\n",
        "    tokens_with_entities.append(lstdata)\n",
        "    return lstdata\n",
        "def createSubEntity(start,end,tag):\n",
        "    s = (int(start),int(end),tag)\n",
        "    return s"
      ],
      "metadata": {
        "id": "qozwgcxgity7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train),len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJeoeFo19l-b",
        "outputId": "f6c84c08-df6d-4081-e758-44e686bf9e69"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(620, 87)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test=[]\n",
        "for a in lstTest:\n",
        "    test.append(get_tokens_with_entities(a))"
      ],
      "metadata": {
        "id": "mT7M-VCpyBbH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "jsonStr = json.dumps(train_data)\n",
        "import json\n",
        "with open('drive/MyDrive/Spacy/train_data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(train_data, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "2YWBWCfMqzpD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_1AoQtndW8m",
        "outputId": "1013743f-6417-4b04-9b33-1f96326a1e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy_transformers\n",
            "  Downloading spacy_transformers-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy_transformers) (1.22.4)\n",
            "Collecting spacy<4.0.0,>=3.5.0\n",
            "  Downloading spacy-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from spacy_transformers) (1.13.1+cu116)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy_transformers) (2.4.6)\n",
            "Collecting transformers<4.27.0,>=3.4.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (4.64.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.0.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.0.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (1.10.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.1.2)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (0.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (23.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (2.25.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (6.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (8.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (57.4.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.5.0->spacy_transformers) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.0->spacy_transformers) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy_transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy_transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<4.27.0,>=3.4.0->spacy_transformers) (2022.6.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (4.0.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.5.0->spacy_transformers) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<4.0.0,>=3.5.0->spacy_transformers) (2.1.2)\n",
            "Installing collected packages: tokenizers, spacy-alignments, huggingface-hub, transformers, spacy, spacy_transformers\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.4\n",
            "    Uninstalling spacy-3.4.4:\n",
            "      Successfully uninstalled spacy-3.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.12.1 spacy-3.5.0 spacy-alignments-0.9.0 spacy_transformers-1.2.2 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.5.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy_transformers\n",
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "-4kqyEGSgJBL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "9iu5513eYxq-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config /content/drive/MyDrive/Spacy1/base_config.cfg /content/drive/MyDrive/Spacy1/config.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ozXD0Si-qJ",
        "outputId": "b5a86383-7204-4b88-d26a-5d1902bd9536"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-04 14:56:26.766691: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-04 14:56:26.766794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-04 14:56:26.766812: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/content/drive/MyDrive/Spacy1/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spacy_doc(file,data):\n",
        "  nlp = spacy.blank(\"en\")\n",
        "  db = DocBin()\n",
        "  for text, annot in tqdm(data):\n",
        "    doc = nlp.make_doc(text)\n",
        "    annot = annot['entities']\n",
        "    ents = []\n",
        "    entity_indices = []\n",
        "    for start, end, label in annot:\n",
        "      skip_entity = False\n",
        "      for idx in range(start,end):\n",
        "        if idx in entity_indices:\n",
        "          skip_entity = True\n",
        "          break\n",
        "      if skip_entity==True:\n",
        "        continue\n",
        "      entity_indices = entity_indices+list(range(start,end))\n",
        "\n",
        "      try:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "      except:\n",
        "        continue\n",
        "      if span is None:\n",
        "        err_data = str([start,end])+\" \"+str(text)+\"\\n\"\n",
        "        file.write(err_data)\n",
        "      else:\n",
        "        ents.append(span)\n",
        "      \n",
        "      doc.ents = ents\n",
        "      db.add(doc)\n",
        "  return db"
      ],
      "metadata": {
        "id": "iHqMTJWGo-_2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gvRXr8UnW7eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('drive/MyDrive/Spacy/error.txt','w')\n",
        "db = get_spacy_doc(file,train)\n",
        "db.to_disk('train_data.spacy')\n",
        "\n",
        "db = get_spacy_doc(file,test)\n",
        "db.to_disk('test_data.spacy')\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79SrwnEi2BuT",
        "outputId": "dd17f3ad-3cf6-4c37-91ad-c40961b5f3c8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 620/620 [00:02<00:00, 282.39it/s]\n",
            "100%|██████████| 87/87 [00:00<00:00, 159.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train /content/drive/MyDrive/Spacy1/config.cfg --output ./outputSpacybert --paths.train ./train_data.spacy --paths.dev ./test_data.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug7D7J3D5oZ_",
        "outputId": "c18364a1-ad58-47c4-ced4-51dc52ca30f7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-04 14:57:05.446340: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-04 14:57:05.446434: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-04 14:57:05.446453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[38;5;2m✔ Created output directory: outputSpacybert\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: outputSpacybert\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-03-04 14:57:14,154] [INFO] Set up nlp object from config\n",
            "[2023-03-04 14:57:14,166] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2023-03-04 14:57:14,169] [INFO] Created vocabulary\n",
            "[2023-03-04 14:57:14,170] [INFO] Finished initializing nlp object\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 4.56kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 226kB/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 349kB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 466k/466k [00:00<00:00, 526kB/s]\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 440M/440M [00:05<00:00, 75.7MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2023-03-04 14:58:03,833] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "  0       0        6784.27    586.22    0.12    0.06    2.44    0.00\n",
            "  1     200      174181.87  41384.63   39.01   27.50   67.07    0.39\n",
            "  2     400        2385.91  19118.97   45.73   31.75   81.71    0.46\n",
            "  3     600         635.78  15316.00   42.55   30.00   73.17    0.43\n",
            "  4     800         733.96  15256.97   88.46   93.24   84.15    0.88\n",
            "  6    1000          20.03  12786.06   81.33   89.71   74.39    0.81\n",
            "  7    1200           7.76  12888.22   85.16   90.41   80.49    0.85\n",
            "  8    1400           8.73  11577.72   80.82   92.19   71.95    0.81\n",
            "  9    1600           7.70  11498.42   82.80   86.67   79.27    0.83\n",
            " 10    1800          16.31  10626.61   84.97   91.55   79.27    0.85\n",
            " 12    2000           7.12   9294.63   79.43   94.92   68.29    0.79\n",
            " 13    2200          23.70   9070.59   81.63   92.31   73.17    0.82\n",
            " 14    2400           8.04   7752.86   85.71   91.67   80.49    0.86\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "outputSpacybert/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/file.zip /content/outputSpacybert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZMkzL0rh_VA",
        "outputId": "5f131211-a06e-4945-c894-f4461775f65e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/outputSpacybert/ (stored 0%)\n",
            "  adding: content/outputSpacybert/model-last/ (stored 0%)\n",
            "  adding: content/outputSpacybert/model-last/tokenizer (deflated 81%)\n",
            "  adding: content/outputSpacybert/model-last/meta.json (deflated 57%)\n",
            "  adding: content/outputSpacybert/model-last/ner/ (stored 0%)\n",
            "  adding: content/outputSpacybert/model-last/ner/moves (deflated 43%)\n",
            "  adding: content/outputSpacybert/model-last/ner/cfg (deflated 33%)\n",
            "  adding: content/outputSpacybert/model-last/ner/model (deflated 8%)\n",
            "  adding: content/outputSpacybert/model-last/config.cfg (deflated 61%)\n",
            "  adding: content/outputSpacybert/model-last/transformer/ (stored 0%)\n",
            "  adding: content/outputSpacybert/model-last/transformer/cfg (stored 0%)\n",
            "  adding: content/outputSpacybert/model-last/transformer/model (deflated 8%)\n",
            "  adding: content/outputSpacybert/model-last/vocab/ (stored 0%)\n",
            "  adding: content/outputSpacybert/model-last/vocab/vectors (deflated 45%)\n",
            "  adding: content/outputSpacybert/model-last/vocab/lookups.bin (stored 0%)\n",
            "  adding: content/outputSpacybert/model-last/vocab/strings.json (deflated 75%)\n",
            "  adding: content/outputSpacybert/model-last/vocab/key2row (stored 0%)\n",
            "  adding: content/outputSpacybert/model-last/vocab/vectors.cfg (stored 0%)\n",
            "  adding: content/outputSpacybert/model-best/ (stored 0%)\n",
            "  adding: content/outputSpacybert/model-best/tokenizer (deflated 81%)\n",
            "  adding: content/outputSpacybert/model-best/meta.json (deflated 57%)\n",
            "  adding: content/outputSpacybert/model-best/ner/ (stored 0%)\n",
            "  adding: content/outputSpacybert/model-best/ner/moves (deflated 43%)\n",
            "  adding: content/outputSpacybert/model-best/ner/cfg (deflated 33%)\n",
            "  adding: content/outputSpacybert/model-best/ner/model (deflated 8%)\n",
            "  adding: content/outputSpacybert/model-best/config.cfg (deflated 61%)\n",
            "  adding: content/outputSpacybert/model-best/transformer/ (stored 0%)\n",
            "  adding: content/outputSpacybert/model-best/transformer/cfg (stored 0%)\n",
            "  adding: content/outputSpacybert/model-best/transformer/model (deflated 8%)\n",
            "  adding: content/outputSpacybert/model-best/vocab/ (stored 0%)\n",
            "  adding: content/outputSpacybert/model-best/vocab/vectors (deflated 45%)\n",
            "  adding: content/outputSpacybert/model-best/vocab/lookups.bin (stored 0%)\n",
            "  adding: content/outputSpacybert/model-best/vocab/strings.json (deflated 75%)\n",
            "  adding: content/outputSpacybert/model-best/vocab/key2row (stored 0%)\n",
            "  adding: content/outputSpacybert/model-best/vocab/vectors.cfg (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "X-_Hz_bZhuYZ",
        "outputId": "8d82fd63-dec0-434f-c551-93a5d3bc5603"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0ef24fa3-7fd0-4a80-840e-ae8374af0439\", \"file.zip\", 811683937)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEST\n"
      ],
      "metadata": {
        "id": "brVuL1PulhJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('outputSpacybert/model-best')"
      ],
      "metadata": {
        "id": "wN2DW_-kljor"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('drive/MyDrive/textInResume.csv')\n",
        "dataTest = df['text'].values.tolist()"
      ],
      "metadata": {
        "id": "t4OM4Xj6lzLF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "i=0\n",
        "\n",
        "bst_pred=[]\n",
        "for d in dataTest:\n",
        "  doc = nlp(d)\n",
        "  print(\"## doc \",i,\" ##\")\n",
        "  person = ''\n",
        "  for ent in doc.ents:\n",
        "    nameRegex = re.compile('[A-Za-z]{2,25} [A-Za-z]{2,25}')\n",
        "    if nameRegex.findall(ent.text)!=[]:\n",
        "      print(ent.text)\n",
        "      person=ent.text\n",
        "  bst_pred.append(person)\n",
        "\n",
        "    #print(ent.text,\"----\",ent.label_)\n",
        "  i = i+1\n",
        "  print(\"   \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWoApGQ1l7y7",
        "outputId": "e78616d0-9aa9-4143-c004-52381bfd30ce"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## doc  0  ##\n",
            "supavit attagomol\n",
            "   \n",
            "## doc  1  ##\n",
            "nisaratwisesbantao bachelor\n",
            "   \n",
            "## doc  2  ##\n",
            "thirawit jirarungroj\n",
            "   \n",
            "## doc  3  ##\n",
            "   \n",
            "## doc  4  ##\n",
            "thanchanok watcharakitphokin\n",
            "   \n",
            "## doc  5  ##\n",
            "|natanop pimonsathian\n",
            "   \n",
            "## doc  6  ##\n",
            "patcharaya anuntasinkul\n",
            "   \n",
            "## doc  7  ##\n",
            "jarrukorn pensalaphan\n",
            "   \n",
            "## doc  8  ##\n",
            "pravittra vimonworachort\n",
            "   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## doc  9  ##\n",
            "   \n",
            "## doc  10  ##\n",
            "purawat ruangsri\n",
            "   \n",
            "## doc  11  ##\n",
            "nutratanon mahakhet\n",
            "   \n",
            "## doc  12  ##\n",
            "kitisak thossaensin\n",
            "   \n",
            "## doc  13  ##\n",
            "suebtas limsaihua\n",
            "   \n",
            "## doc  14  ##\n",
            "   \n",
            "## doc  15  ##\n",
            "chayanit sripradit\n",
            "   \n",
            "## doc  16  ##\n",
            "pimnares puto\n",
            "   \n",
            "## doc  17  ##\n",
            "saran thitawiriyayos\n",
            "   \n",
            "## doc  18  ##\n",
            "pakpoom poodsud\n",
            "   \n",
            "## doc  19  ##\n",
            "kanittha setthapitayakul\n",
            "   \n",
            "## doc  20  ##\n",
            "parweenuch duangdenphatsawron\n",
            "   \n",
            "## doc  21  ##\n",
            "pawith panyasirikul\n",
            "   \n",
            "## doc  22  ##\n",
            "chotitouch supalanunt\n",
            "   \n",
            "## doc  23  ##\n",
            "aussadach masun\n",
            "   \n",
            "## doc  24  ##\n",
            "teeratach jearapaganon\n",
            "   \n",
            "## doc  25  ##\n",
            "pratan srikamonpattanawut\n",
            "   \n",
            "## doc  26  ##\n",
            "   \n",
            "## doc  27  ##\n",
            "chayanon juntarapartsavorn\n",
            "   \n",
            "## doc  28  ##\n",
            "narurong saeheng\n",
            "   \n",
            "## doc  29  ##\n",
            "supachai sumeteenarumit\n",
            "   \n",
            "## doc  30  ##\n",
            "ittichote sornmeethong\n",
            "   \n",
            "## doc  31  ##\n",
            "kamolchai suebnipon\n",
            "   \n",
            "## doc  32  ##\n",
            "   \n",
            "## doc  33  ##\n",
            "nattachai noogure\n",
            "   \n",
            "## doc  34  ##\n",
            "saksorn pawasakarin\n",
            "   \n",
            "## doc  35  ##\n",
            "navapuvadol uraikul\n",
            "   \n",
            "## doc  36  ##\n",
            "harit piyapornthana\n",
            "   \n",
            "## doc  37  ##\n",
            "setthawuth kangwansakol\n",
            "   \n",
            "## doc  38  ##\n",
            "miss.ratchanok angkhahad\n",
            "   \n",
            "## doc  39  ##\n",
            "veerachaimitmorn creativity\n",
            "   \n",
            "## doc  40  ##\n",
            "phanchita korsanankittipat\n",
            "   \n",
            "## doc  41  ##\n",
            "suphakit sangthong\n",
            "   \n",
            "## doc  42  ##\n",
            "   \n",
            "## doc  43  ##\n",
            "jitawat chanpraneet\n",
            "   \n",
            "## doc  44  ##\n",
            "   \n",
            "## doc  45  ##\n",
            "suwan panjanapongchai\n",
            "   \n",
            "## doc  46  ##\n",
            "saksorn pawasakarin\n",
            "   \n",
            "## doc  47  ##\n",
            "kamolwan penpetch\n",
            "   \n",
            "## doc  48  ##\n",
            "autsadang somboonphol\n",
            "   \n",
            "## doc  49  ##\n",
            "chanon sattrupinat\n",
            "   \n",
            "## doc  50  ##\n",
            "   \n",
            "## doc  51  ##\n",
            "krittapad harnchang\n",
            "   \n",
            "## doc  52  ##\n",
            "   \n",
            "## doc  53  ##\n",
            "suchit rojanapatanasombat\n",
            "   \n",
            "## doc  54  ##\n",
            "   \n",
            "## doc  55  ##\n",
            "tharathep chuayrod\n",
            "   \n",
            "## doc  56  ##\n",
            "nonthawat aphiwong\n",
            "   \n",
            "## doc  57  ##\n",
            "tititab srisookco\n",
            "   \n",
            "## doc  58  ##\n",
            "nuttamol janmanee\n",
            "   \n",
            "## doc  59  ##\n",
            "apinop soisuwan\n",
            "   \n",
            "## doc  60  ##\n",
            "kritdanai peerapolchaikul\n",
            "   \n",
            "## doc  61  ##\n",
            "kittiphong chankong\n",
            "   \n",
            "## doc  62  ##\n",
            "pakavich veeranarapanich\n",
            "   \n",
            "## doc  63  ##\n",
            "tongkorn pawananan\n",
            "   \n",
            "## doc  64  ##\n",
            "pisarnwate jitvimol\n",
            "   \n",
            "## doc  65  ##\n",
            "   \n",
            "## doc  66  ##\n",
            "peerawish tawantarong\n",
            "   \n",
            "## doc  67  ##\n",
            "   \n",
            "## doc  68  ##\n",
            "komson packdeearporn\n",
            "   \n",
            "## doc  69  ##\n",
            "ektanat pupat\n",
            "   \n",
            "## doc  70  ##\n",
            "thapaneesuklapkit logisticsengineer\n",
            "   \n",
            "## doc  71  ##\n",
            "pummarast amornmaneekul\n",
            "   \n",
            "## doc  72  ##\n",
            "haruthai jankrajung\n",
            "   \n",
            "## doc  73  ##\n",
            "apiwut kittiparikun\n",
            "   \n",
            "## doc  74  ##\n",
            "trichet surichai\n",
            "   \n",
            "## doc  75  ##\n",
            "arthit thetkham\n",
            "   \n",
            "## doc  76  ##\n",
            "yonlada nedluecha\n",
            "   \n",
            "## doc  77  ##\n",
            "   \n",
            "## doc  78  ##\n",
            "tussanakorn rattanaburee\n",
            "   \n",
            "## doc  79  ##\n",
            "natakit lalitputtichoke\n",
            "   \n",
            "## doc  80  ##\n",
            "thummarat paklao\n",
            "   \n",
            "## doc  81  ##\n",
            "patipan mata\n",
            "   \n",
            "## doc  82  ##\n",
            "tanakrid chanburi\n",
            "   \n",
            "## doc  83  ##\n",
            "sarakrit thahanthai\n",
            "   \n",
            "## doc  84  ##\n",
            "naruedom kiatikoon\n",
            "   \n",
            "## doc  85  ##\n",
            "pattarapon buathong\n",
            "   \n",
            "## doc  86  ##\n",
            "wittawat hormhuan\n",
            "   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bst_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VwaRBJFQXzR",
        "outputId": "7258390d-e2ce-40d2-a056-01f44951d4a9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['supavit attagomol',\n",
              " 'nisaratwisesbantao bachelor',\n",
              " 'thirawit jirarungroj',\n",
              " '',\n",
              " 'thanchanok watcharakitphokin',\n",
              " '|natanop pimonsathian',\n",
              " 'patcharaya anuntasinkul',\n",
              " 'jarrukorn pensalaphan',\n",
              " 'pravittra vimonworachort',\n",
              " '',\n",
              " 'purawat ruangsri',\n",
              " 'nutratanon mahakhet',\n",
              " 'kitisak thossaensin',\n",
              " 'suebtas limsaihua',\n",
              " '',\n",
              " 'chayanit sripradit',\n",
              " 'pimnares puto',\n",
              " 'saran thitawiriyayos',\n",
              " 'pakpoom poodsud',\n",
              " 'kanittha setthapitayakul',\n",
              " 'parweenuch duangdenphatsawron',\n",
              " 'pawith panyasirikul',\n",
              " 'chotitouch supalanunt',\n",
              " 'aussadach masun',\n",
              " 'teeratach jearapaganon',\n",
              " 'pratan srikamonpattanawut',\n",
              " '',\n",
              " 'chayanon juntarapartsavorn',\n",
              " 'narurong saeheng',\n",
              " 'supachai sumeteenarumit',\n",
              " 'ittichote sornmeethong',\n",
              " 'kamolchai suebnipon',\n",
              " '',\n",
              " 'nattachai noogure',\n",
              " 'saksorn pawasakarin',\n",
              " 'navapuvadol uraikul',\n",
              " 'harit piyapornthana',\n",
              " 'setthawuth kangwansakol',\n",
              " 'miss.ratchanok angkhahad',\n",
              " 'veerachaimitmorn creativity',\n",
              " 'phanchita korsanankittipat',\n",
              " 'suphakit sangthong',\n",
              " '',\n",
              " 'jitawat chanpraneet',\n",
              " '',\n",
              " 'suwan panjanapongchai',\n",
              " 'saksorn pawasakarin',\n",
              " 'kamolwan penpetch',\n",
              " 'autsadang somboonphol',\n",
              " 'chanon sattrupinat',\n",
              " '',\n",
              " 'krittapad harnchang',\n",
              " '',\n",
              " 'suchit rojanapatanasombat',\n",
              " '',\n",
              " 'tharathep chuayrod',\n",
              " 'nonthawat aphiwong',\n",
              " 'tititab srisookco',\n",
              " 'nuttamol janmanee',\n",
              " 'apinop soisuwan',\n",
              " 'kritdanai peerapolchaikul',\n",
              " 'kittiphong chankong',\n",
              " 'pakavich veeranarapanich',\n",
              " 'tongkorn pawananan',\n",
              " 'pisarnwate jitvimol',\n",
              " '',\n",
              " 'peerawish tawantarong',\n",
              " '',\n",
              " 'komson packdeearporn',\n",
              " 'ektanat pupat',\n",
              " 'thapaneesuklapkit logisticsengineer',\n",
              " 'pummarast amornmaneekul',\n",
              " 'haruthai jankrajung',\n",
              " 'apiwut kittiparikun',\n",
              " 'trichet surichai',\n",
              " 'arthit thetkham',\n",
              " 'yonlada nedluecha',\n",
              " '',\n",
              " 'tussanakorn rattanaburee',\n",
              " 'natakit lalitputtichoke',\n",
              " 'thummarat paklao',\n",
              " 'patipan mata',\n",
              " 'tanakrid chanburi',\n",
              " 'sarakrit thahanthai',\n",
              " 'naruedom kiatikoon',\n",
              " 'pattarapon buathong',\n",
              " 'wittawat hormhuan']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlpLst = spacy.load('outputSpacybert/model-last')"
      ],
      "metadata": {
        "id": "qrcJN2cS4O62"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "i=0\n",
        "lst_pred=[]\n",
        "for d in dataTest:\n",
        "  doc = nlpLst(d)\n",
        "  print(\"## doc \",i,\" ##\")\n",
        "  person = ''\n",
        "  for ent in doc.ents:\n",
        "    nameRegex = re.compile('[A-Za-z]{2,25} [A-Za-z]{2,25}')\n",
        "    if nameRegex.findall(ent.text)!=[]:\n",
        "      print(ent.text)\n",
        "      person=ent.text\n",
        "  lst_pred.append(person)\n",
        "\n",
        "    #print(ent.text,\"----\",ent.label_)\n",
        "  i = i+1\n",
        "  print(\"   \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woU7-Dvw4Uwt",
        "outputId": "9132681f-8589-42b2-e4fc-f43907149dbd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## doc  0  ##\n",
            "supavit attagomol\n",
            "   \n",
            "## doc  1  ##\n",
            "nisaratwisesbantao bachelor\n",
            "   \n",
            "## doc  2  ##\n",
            "thirawit jirarungroj\n",
            "   \n",
            "## doc  3  ##\n",
            "   \n",
            "## doc  4  ##\n",
            "thanchanok watcharakitphokin\n",
            "   \n",
            "## doc  5  ##\n",
            "|natanop pimonsathian\n",
            "   \n",
            "## doc  6  ##\n",
            "patcharaya anuntasinkul\n",
            "   \n",
            "## doc  7  ##\n",
            "jarrukorn pensalaphan\n",
            "   \n",
            "## doc  8  ##\n",
            "pravittra vimonworachort\n",
            "   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## doc  9  ##\n",
            "   \n",
            "## doc  10  ##\n",
            "purawat ruangsri\n",
            "   \n",
            "## doc  11  ##\n",
            "nutratanon mahakhet\n",
            "   \n",
            "## doc  12  ##\n",
            "kitisak thossaensin\n",
            "   \n",
            "## doc  13  ##\n",
            "suebtas limsaihua\n",
            "   \n",
            "## doc  14  ##\n",
            "   \n",
            "## doc  15  ##\n",
            "chayanit sripradit\n",
            "   \n",
            "## doc  16  ##\n",
            "pimnares puto\n",
            "   \n",
            "## doc  17  ##\n",
            "saran thitawiriyayos\n",
            "   \n",
            "## doc  18  ##\n",
            "pakpoom poodsud\n",
            "   \n",
            "## doc  19  ##\n",
            "kanittha setthapitayakul\n",
            "   \n",
            "## doc  20  ##\n",
            "parweenuch duangdenphatsawron\n",
            "   \n",
            "## doc  21  ##\n",
            "pawith panyasirikul\n",
            "   \n",
            "## doc  22  ##\n",
            "chotitouch supalanunt\n",
            "   \n",
            "## doc  23  ##\n",
            "aussadach masun\n",
            "   \n",
            "## doc  24  ##\n",
            "teeratach jearapaganon\n",
            "   \n",
            "## doc  25  ##\n",
            "pratan srikamonpattanawut\n",
            "   \n",
            "## doc  26  ##\n",
            "   \n",
            "## doc  27  ##\n",
            "chayanon juntarapartsavorn\n",
            "   \n",
            "## doc  28  ##\n",
            "narurong saeheng\n",
            "   \n",
            "## doc  29  ##\n",
            "supachai sumeteenarumit\n",
            "   \n",
            "## doc  30  ##\n",
            "ittichote sornmeethong\n",
            "   \n",
            "## doc  31  ##\n",
            "kamolchai suebnipon\n",
            "   \n",
            "## doc  32  ##\n",
            "   \n",
            "## doc  33  ##\n",
            "nattachai noogure\n",
            "   \n",
            "## doc  34  ##\n",
            "saksorn pawasakarin\n",
            "   \n",
            "## doc  35  ##\n",
            "navapuvadol uraikul\n",
            "   \n",
            "## doc  36  ##\n",
            "harit piyapornthana\n",
            "   \n",
            "## doc  37  ##\n",
            "setthawuth kangwansakol\n",
            "   \n",
            "## doc  38  ##\n",
            "   \n",
            "## doc  39  ##\n",
            "veerachaimitmorn creativity\n",
            "   \n",
            "## doc  40  ##\n",
            "phanchita korsanankittipat\n",
            "   \n",
            "## doc  41  ##\n",
            "suphakit sangthong\n",
            "   \n",
            "## doc  42  ##\n",
            "   \n",
            "## doc  43  ##\n",
            "jitawat chanpraneet\n",
            "   \n",
            "## doc  44  ##\n",
            "anwar rajawana\n",
            "   \n",
            "## doc  45  ##\n",
            "suwan panjanapongchai\n",
            "   \n",
            "## doc  46  ##\n",
            "saksorn pawasakarin\n",
            "   \n",
            "## doc  47  ##\n",
            "kamolwan penpetch\n",
            "   \n",
            "## doc  48  ##\n",
            "autsadang somboonphol\n",
            "   \n",
            "## doc  49  ##\n",
            "chanon sattrupinat\n",
            "   \n",
            "## doc  50  ##\n",
            "   \n",
            "## doc  51  ##\n",
            "   \n",
            "## doc  52  ##\n",
            "   \n",
            "## doc  53  ##\n",
            "suchit rojanapatanasombat\n",
            "   \n",
            "## doc  54  ##\n",
            "   \n",
            "## doc  55  ##\n",
            "tharathep chuayrod\n",
            "   \n",
            "## doc  56  ##\n",
            "nonthawat aphiwong\n",
            "   \n",
            "## doc  57  ##\n",
            "tititab srisookco\n",
            "   \n",
            "## doc  58  ##\n",
            "nuttamol janmanee\n",
            "   \n",
            "## doc  59  ##\n",
            "apinop soisuwan\n",
            "   \n",
            "## doc  60  ##\n",
            "kritdanai peerapolchaikul\n",
            "   \n",
            "## doc  61  ##\n",
            "kittiphong chankong\n",
            "   \n",
            "## doc  62  ##\n",
            "pakavich veeranarapanich\n",
            "   \n",
            "## doc  63  ##\n",
            "   \n",
            "## doc  64  ##\n",
            "pisarnwate jitvimol\n",
            "   \n",
            "## doc  65  ##\n",
            "pilikamin an\n",
            "   \n",
            "## doc  66  ##\n",
            "peerawish tawantarong\n",
            "   \n",
            "## doc  67  ##\n",
            "   \n",
            "## doc  68  ##\n",
            "komson packdeearporn\n",
            "   \n",
            "## doc  69  ##\n",
            "ektanat pupat\n",
            "   \n",
            "## doc  70  ##\n",
            "thapaneesuklapkit logisticsengineer\n",
            "   \n",
            "## doc  71  ##\n",
            "pummarast amornmaneekul\n",
            "   \n",
            "## doc  72  ##\n",
            "haruthai jankrajung\n",
            "   \n",
            "## doc  73  ##\n",
            "   \n",
            "## doc  74  ##\n",
            "trichet surichai\n",
            "   \n",
            "## doc  75  ##\n",
            "arthit thetkham\n",
            "   \n",
            "## doc  76  ##\n",
            "yonlada nedluecha\n",
            "   \n",
            "## doc  77  ##\n",
            "   \n",
            "## doc  78  ##\n",
            "   \n",
            "## doc  79  ##\n",
            "natakit lalitputtichoke\n",
            "   \n",
            "## doc  80  ##\n",
            "thummarat paklao\n",
            "   \n",
            "## doc  81  ##\n",
            "patipan mata\n",
            "   \n",
            "## doc  82  ##\n",
            "tanakrid chanburi\n",
            "   \n",
            "## doc  83  ##\n",
            "sarakrit thahanthai\n",
            "   \n",
            "## doc  84  ##\n",
            "naruedom kiatikoon\n",
            "   \n",
            "## doc  85  ##\n",
            "pattarapon buathong\n",
            "   \n",
            "## doc  86  ##\n",
            "wittawat hormhuan\n",
            "   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yGbWMRyQyON",
        "outputId": "1bb67d5d-bbb6-42ce-de31-e63b647700c7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['supavit attagomol',\n",
              " 'nisaratwisesbantao bachelor',\n",
              " 'thirawit jirarungroj',\n",
              " '',\n",
              " 'thanchanok watcharakitphokin',\n",
              " '|natanop pimonsathian',\n",
              " 'patcharaya anuntasinkul',\n",
              " 'jarrukorn pensalaphan',\n",
              " 'pravittra vimonworachort',\n",
              " '',\n",
              " 'purawat ruangsri',\n",
              " 'nutratanon mahakhet',\n",
              " 'kitisak thossaensin',\n",
              " 'suebtas limsaihua',\n",
              " '',\n",
              " 'chayanit sripradit',\n",
              " 'pimnares puto',\n",
              " 'saran thitawiriyayos',\n",
              " 'pakpoom poodsud',\n",
              " 'kanittha setthapitayakul',\n",
              " 'parweenuch duangdenphatsawron',\n",
              " 'pawith panyasirikul',\n",
              " 'chotitouch supalanunt',\n",
              " 'aussadach masun',\n",
              " 'teeratach jearapaganon',\n",
              " 'pratan srikamonpattanawut',\n",
              " '',\n",
              " 'chayanon juntarapartsavorn',\n",
              " 'narurong saeheng',\n",
              " 'supachai sumeteenarumit',\n",
              " 'ittichote sornmeethong',\n",
              " 'kamolchai suebnipon',\n",
              " '',\n",
              " 'nattachai noogure',\n",
              " 'saksorn pawasakarin',\n",
              " 'navapuvadol uraikul',\n",
              " 'harit piyapornthana',\n",
              " 'setthawuth kangwansakol',\n",
              " '',\n",
              " 'veerachaimitmorn creativity',\n",
              " 'phanchita korsanankittipat',\n",
              " 'suphakit sangthong',\n",
              " '',\n",
              " 'jitawat chanpraneet',\n",
              " 'anwar rajawana',\n",
              " 'suwan panjanapongchai',\n",
              " 'saksorn pawasakarin',\n",
              " 'kamolwan penpetch',\n",
              " 'autsadang somboonphol',\n",
              " 'chanon sattrupinat',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'suchit rojanapatanasombat',\n",
              " '',\n",
              " 'tharathep chuayrod',\n",
              " 'nonthawat aphiwong',\n",
              " 'tititab srisookco',\n",
              " 'nuttamol janmanee',\n",
              " 'apinop soisuwan',\n",
              " 'kritdanai peerapolchaikul',\n",
              " 'kittiphong chankong',\n",
              " 'pakavich veeranarapanich',\n",
              " '',\n",
              " 'pisarnwate jitvimol',\n",
              " 'pilikamin an',\n",
              " 'peerawish tawantarong',\n",
              " '',\n",
              " 'komson packdeearporn',\n",
              " 'ektanat pupat',\n",
              " 'thapaneesuklapkit logisticsengineer',\n",
              " 'pummarast amornmaneekul',\n",
              " 'haruthai jankrajung',\n",
              " '',\n",
              " 'trichet surichai',\n",
              " 'arthit thetkham',\n",
              " 'yonlada nedluecha',\n",
              " '',\n",
              " '',\n",
              " 'natakit lalitputtichoke',\n",
              " 'thummarat paklao',\n",
              " 'patipan mata',\n",
              " 'tanakrid chanburi',\n",
              " 'sarakrit thahanthai',\n",
              " 'naruedom kiatikoon',\n",
              " 'pattarapon buathong',\n",
              " 'wittawat hormhuan']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dfName = pd.read_csv('drive/MyDrive/resumeData.csv')\n",
        "lstTrue = dfName['PERSON'].values.tolist()"
      ],
      "metadata": {
        "id": "1LIfpYg8Q-mD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrix of model best"
      ],
      "metadata": {
        "id": "eYe4P_MgR7j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "f1DqJxWcRBR2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array(lstTrue)\n",
        "y_pred = np.array(bst_pred)"
      ],
      "metadata": {
        "id": "bbC32lp_SDPZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(y_true, y_pred, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KupU5hpTQnC",
        "outputId": "95d40b9f-9e9d-4e6e-f75d-7c3ca83c6d95"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7068965517241379, 0.7126436781609196, 0.7088122605363985, None)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(y_true, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TClS9Oy0UYWs",
        "outputId": "d5c9330d-2846-4e90-bd8d-b66a97e2d52d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6212121212121212, 0.6262626262626263, 0.6228956228956228, None)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(y_true, y_pred, average='micro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUp-nWgpUe9K",
        "outputId": "783bdf95-82d7-45a5-8b98-a8b2003b131e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7126436781609196, 0.7126436781609196, 0.7126436781609196, None)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(y_true, y_pred, average=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj9pZ2ToUiVw",
        "outputId": "aa568e74-d2ac-4cb6-a216-2dcc7a67b81b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
              "        1. , 1. , 1. , 1. , 1. , 1. , 0. , 1. , 1. , 1. , 0. , 1. , 1. ,\n",
              "        1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 0. , 0. , 1. ,\n",
              "        1. , 1. , 1. , 0. , 1. , 0. , 0. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
              "        1. , 1. , 1. , 1. , 1. , 0. , 1. , 1. , 0. , 1. , 1. , 1. , 1. ,\n",
              "        0. , 0. , 0. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 0. , 1. , 0. ,\n",
              "        1. , 1. , 1. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 1. , 1. , 1. ,\n",
              "        1. , 1. , 0. , 0. , 1. , 0. , 1. , 0. ]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.]),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.        ,\n",
              "        1.        , 1.        , 1.        , 0.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.        , 1.        , 0.        ,\n",
              "        0.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.        , 1.        , 1.        ,\n",
              "        0.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.        , 0.        , 0.        , 0.66666667, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.        , 1.        , 0.        , 1.        , 1.        ,\n",
              "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.        , 0.        ,\n",
              "        1.        , 0.        , 1.        , 0.        ]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrix of model last"
      ],
      "metadata": {
        "id": "j-JzmlkrUugl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.array(lstTrue)\n",
        "y_pred = np.array(lst_pred)"
      ],
      "metadata": {
        "id": "kyE3oKUcUwTd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(y_true, y_pred, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JDu38rXUzLc",
        "outputId": "00e2e544-a850-4a99-bd3b-db3831c66243"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6724137931034483, 0.6781609195402298, 0.6743295019157088, None)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(y_true, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqCctstSU3rb",
        "outputId": "da3a7a21-a84e-4670-8d2d-81635ed3f7f5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5909090909090909, 0.5959595959595959, 0.5925925925925927, None)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(y_true, y_pred, average='micro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StcV527bU65w",
        "outputId": "c3b2fff3-425e-4948-8dde-78e24f1d7a67"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6781609195402298, 0.6781609195402298, 0.6781609195402298, None)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(y_true, y_pred, average=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPs2PraGU8ro",
        "outputId": "1ceb6437-00b1-494c-cc75-0ab4f9dc5eeb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ,\n",
              "        1. , 0. , 1. , 1. , 1. , 1. , 0. , 1. , 1. , 1. , 0. , 1. , 1. ,\n",
              "        1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 0. , 0. , 1. , 1. ,\n",
              "        1. , 1. , 0. , 1. , 0. , 0. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
              "        1. , 1. , 1. , 1. , 0. , 0. , 1. , 1. , 0. , 1. , 1. , 1. , 1. ,\n",
              "        0. , 0. , 0. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 0. , 1. , 0. ,\n",
              "        1. , 1. , 1. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 1. , 1. , 0. ,\n",
              "        1. , 0. , 0. , 0. , 1. , 0. , 1. , 0. ]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
              "        1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.]),\n",
              " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 1.        , 1.        , 0.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.        ,\n",
              "        1.        , 1.        , 1.        , 0.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.        , 1.        , 0.        , 0.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
              "        0.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.        , 0.        , 0.        , 0.66666667, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.        , 1.        , 0.        , 1.        , 1.        ,\n",
              "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
              "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
              "        1.        , 0.        , 1.        , 0.        ]),\n",
              " array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}